name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:  # Allow manual triggering

# Cancel in-progress runs for the same workflow and branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

# Least-privilege permissions: read-only for most jobs, write only for artifacts
permissions:
  contents: read
  pull-requests: read
  checks: write  # Required for Codecov status checks

jobs:
  dependency-check:
    name: Dependency Drift Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install tomli (for Python < 3.11 compatibility)
        run: |
          python -m pip install --upgrade pip
          python -m pip install tomli

      - name: Validate dependency consistency
        run: python scripts/validate_dependencies.py

  docs-validation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install PyYAML (for metadata validation)
        run: |
          python -m pip install --upgrade pip
          python -m pip install pyyaml

      - name: Verify documentation links
        id: verify_docs
        run: |
          python scripts/verify_docs.py
        continue-on-error: false

      - name: Test code examples in documentation
        id: doc_tests
        run: |
          python scripts/run_doc_tests.py
        continue-on-error: false

      - name: Check documentation synchronization
        id: doc_sync
        run: |
          python scripts/check_doc_sync.py --format text
        continue-on-error: true  # Non-blocking: many false positives from examples

      - name: Documentation Validation Summary
        if: always()
        run: |
          echo "## Documentation Validation Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.verify_docs.outcome }}" == "success" ] && [ "${{ steps.doc_tests.outcome }}" == "success" ]; then
            echo "✅ All documentation checks passed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Checks Performed:" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ Internal link validation" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ File reference validation" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ Frontmatter metadata validation (for files with frontmatter)" >> $GITHUB_STEP_SUMMARY
            if [ "${{ steps.doc_tests.outcome }}" == "success" ]; then
              echo "- ✅ Code example syntax validation" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ❌ Code example syntax validation (failed)" >> $GITHUB_STEP_SUMMARY
            fi
            if [ "${{ steps.doc_sync.outcome }}" == "success" ]; then
              echo "- ✅ Documentation synchronization check" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ⚠️ Documentation synchronization check (warnings found, non-blocking)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "❌ **Documentation validation failed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Issues Found:" >> $GITHUB_STEP_SUMMARY
            echo "Broken links, file references, or metadata issues were detected. Review the workflow logs for details." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### How to Fix:" >> $GITHUB_STEP_SUMMARY
            echo "1. Run \`python scripts/verify_docs.py\` locally to see all errors" >> $GITHUB_STEP_SUMMARY
            echo "2. Run \`python scripts/run_doc_tests.py\` to test code examples" >> $GITHUB_STEP_SUMMARY
            echo "3. Fix broken links or update file references" >> $GITHUB_STEP_SUMMARY
            echo "4. Fix syntax errors in code examples" >> $GITHUB_STEP_SUMMARY
            echo "5. For metadata issues, see [Documentation Metadata Standards](docs/DOCUMENTATION_METADATA_STANDARDS.md)" >> $GITHUB_STEP_SUMMARY
            echo "6. Some references may be false positives (external URLs, code examples) - review carefully" >> $GITHUB_STEP_SUMMARY
          fi

  lint:
    name: Lint and Format Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev]"

      - name: Ruff (lint)
        run: ruff check .

      - name: Ruff (format check)
        run: ruff format --check .

  type-check:
    name: Type Checking
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev]"

      - name: "Mypy (staged: core/workflow/context7)"
        run: python -m mypy tapps_agents/core tapps_agents/workflow tapps_agents/context7

  test:
    name: Test (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.13"]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install package (dev)
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev]"
          # Note: For reproducible builds, can use: pip install -r requirements-dev-lock.txt

      - name: Run tests
        id: test
        run: |
          python -m pytest tests/ \
            --junitxml=junit-ci.xml \
            --cov=tapps_agents \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=40 \
            --tb=short \
            -v

      - name: Upload JUnit report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: junit-ci
          path: junit-ci.xml
          retention-days: 30

      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-ci
          path: coverage.xml
          retention-days: 30

      - name: Upload coverage to Codecov
        if: always()
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Extract coverage percentage
        if: always()
        id: coverage
        run: |
          if [ -f coverage.xml ]; then
            # Extract total coverage percentage from coverage.xml
            COVERAGE=$(python -c "
            import xml.etree.ElementTree as ET
            tree = ET.parse('coverage.xml')
            root = tree.getroot()
            total = float(root.get('line-rate', 0)) * 100
            print(f'{total:.2f}')
            ")
            echo "percentage=$COVERAGE" >> $GITHUB_OUTPUT
            echo "Coverage: $COVERAGE%"
          else
            echo "percentage=0.00" >> $GITHUB_OUTPUT
            echo "Coverage: No coverage file found"
          fi

      - name: Test Summary
        if: always()
        run: |
          echo "## CI Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.test.outcome }}" == "success" ]; then
            echo "✅ All tests passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Tests failed** - Check artifacts for details." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Debugging Tips:" >> $GITHUB_STEP_SUMMARY
            echo "- Review the JUnit XML artifact for test failure details" >> $GITHUB_STEP_SUMMARY
            echo "- Check test output in the workflow logs" >> $GITHUB_STEP_SUMMARY
            echo "- Run tests locally: \`pytest tests/\`" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Coverage Report" >> $GITHUB_STEP_SUMMARY
          COVERAGE="${{ steps.coverage.outputs.percentage }}"
          echo "**Coverage: $COVERAGE%**" >> $GITHUB_STEP_SUMMARY
          if [ -n "$COVERAGE" ]; then
            # Use Python for comparison instead of bc (more reliable)
            COVERAGE_CHECK=$(python3 -c "coverage=float('$COVERAGE'); print('1' if coverage < 40.0 else '0')")
            if [ "$COVERAGE_CHECK" == "1" ]; then
              echo "⚠️ **Coverage below 40% threshold**" >> $GITHUB_STEP_SUMMARY
            else
              echo "✅ Coverage meets 40% threshold" >> $GITHUB_STEP_SUMMARY
            fi
            # Also show if below target (75%)
            TARGET_CHECK=$(python3 -c "coverage=float('$COVERAGE'); print('1' if coverage < 75.0 else '0')")
            if [ "$TARGET_CHECK" == "1" ]; then
              echo "ℹ️ *Target coverage is 75%* (currently improving from 40%)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "⚠️ Coverage percentage not available" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "View detailed coverage report in the coverage-ci artifact or on [Codecov](https://codecov.io/gh/${{ github.repository }})." >> $GITHUB_STEP_SUMMARY
