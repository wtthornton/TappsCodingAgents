{
  "library": "storage_models",
  "topic": "common-mistakes",
  "documentation": {
    "content": "## Configure Error Handling Strategies\n\n```typescript\n// Development: Stop on first error to debug quickly\nawait evaluate(dataset, metrics, { throwOnError: true })\n\n// Production: Collect all errors for analysis\nconst results = await evaluate(dataset, metrics, { throwOnError: false })\n\n// Check results for errors\ndataset.forEach((sample, index) => {\n  const result = results[index]\n  if (result.errors?.length > 0) {\n    console.error('Sample failed:', sample.query, result.errors)\n  }\n})\n```\n\n## Configure FactualCorrectness Metric (JavaScript)\n\n```javascript\nconst metric = new FactualCorrectness({\n  model: openai('gpt-4o'),\n  mode: 'precision', // or 'recall', 'f1'\n  atomicity: 'high', // Granularity of claim decomposition\n  coverage: 'high', // Thoroughness of evaluation\n})\n```\n\n## Example Multi-Hop Abstract Questions (Text)\n\n```text\n// TypeScript documentation\n\"How does TypeScript's type system improve code quality?\"\n\"What are the tradeoffs between different typing approaches?\"\n\"How do generics relate to type safety and reusability?\"\n\n// Architecture documentation\n\"How do microservices compare to monolithic architectures?\"\n\"What factors influence database selection for a project?\"\n\"How does caching improve system performance?\"\n```\n\n## Open Evals: Best Practice - Transform Order\n\n```javascript\n// Good: summarize before chunking\nawait transform(graph)\n  .pipe(summarize(llm)) // Document-level\n  .pipe(chunk(splitter)) // Then split\n  .pipe(embed(embedModel)) // Then embed chunks\n  .apply()\n\n// Bad: chunking before summarizing loses document context\nawait transform(graph)\n  .pipe(chunk(splitter)) // Splits document\n  .pipe(summarize(llm)) // Can't summarize chunks effectively!\n  .apply()\n```\n\n## Multi-Turn Sample Structure\n\n```json\n{\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"Hello!\" },\n    { \"role\": \"assistant\", \"content\": \"Hi! How can I help?\" },\n    { \"role\": \"user\", \"content\": \"Tell me about Paris\" },\n    { \"role\": \"assistant\", \"content\": \"Paris is the capital of France...\" }\n  ]\n}\n```\n\n## Skip Ground Truth Generation for Faster Queries with JavaScript\n\n```javascript\nconst samples = await synthesize({\n  graph,\n  synthesizers,\n  personas,\n  count: 10,\n  config: { generateGroundTruth: false }, // Only generate queries\n})\n```\n\n## Initialize Faithfulness and FactualCorrectness Metrics\n\n```javascript\nimport { Faithfulness, FactualCorrectness } from '@open-evals/metrics'\nimport { openai } from '@ai-sdk/openai'\n\n// For RAG applications - check if responses are grounded in context\nconst faithfulness = new Faithfulness({\n  model: openai('gpt-4o-mini'),\n})\n\n// For Q&A systems - check accuracy against reference answers\nconst factualCorrectness = new FactualCorrectness({\n  model: openai('gpt-4o-mini'),\n  mode: 'f1',\n})\n```\n\n## Run Evaluations with Default Settings\n\n```typescript\nimport { evaluate, EvaluationDataset } from '@open-evals/core'\nimport { Faithfulness } from '@open-evals/metrics'\nimport { openai } from '@ai-sdk/openai'\n\nconst dataset = new EvaluationDataset([\n  /* samples */\n])\nconst metrics = [new Faithfulness({ model: openai('gpt-4o-mini') })]\n\nconst results = await evaluate(dataset, metrics)\nconsole.log(results.statistics.averages) // { faithfulness: 0.92 }\n```\n\n## Configure Evaluation Run Options\n\n```javascript\nawait evaluate(dataset, metrics, {\n  concurrency: 10, // Number of samples to evaluate in parallel (default: 10)\n  throwOnError: false, // Whether to stop on first error or collect all results\n  metadata: { exp: '001' }, // Custom data to attach to this evaluation run\n})\n```\n\n## Example Generated Questions (TypeScript & API)\n\n```plaintext\n// TypeScript documentation\n'What is the syntax for optional properties in TypeScript?'\n'How do you declare a string array in TypeScript?'\n'What does the readonly modifier do in TypeScript?'\n\n// API documentation\n'What HTTP method does the /users endpoint accept?'\n'What is the rate limit for the search API?'\n'What format does the API return error messages in?'\n```",
    "library": "evaluation_models",
    "topic": "common-mistakes",
    "source": "fuzzy_match"
  },
  "source": "fuzzy_match",
  "saved_at": "2026-01-30T18:28:14.386769"
}