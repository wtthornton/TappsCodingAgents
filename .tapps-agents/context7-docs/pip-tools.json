{
  "library": "pip-tools",
  "topic": null,
  "documentation": {
    "content": "## Pickling Support for Simple Cache Instances\n\n```python\nimport pickle\nfrom cachetools import LRUCache\n\ncache = LRUCache(maxsize=5)\ncache['key1'] = 'value1'\ncache['key2'] = 'value2'\n\nserialized_cache = pickle.dumps(cache)\ndeserialized_cache = pickle.loads(serialized_cache)\n\nprint(deserialized_cache.get('key1'))\n```\n\n## PepStore Example\n\n```python\n   ...     def __missing__(self, key):\n   ...         \"\"\"Retrieve text of a Python Enhancement Proposal\"\"\"\n   ...         url = 'http://www.python.org/dev/peps/pep-%04d/' % key\n   ...         with urllib.request.urlopen(url) as s:\n   ...             pep = s.read()\n   ...             self[key] = pep  # store text in cache\n   ...             return pep\n\n   >>> peps = PepStore(maxsize=4)\n   >>> for n in 8, 9, 290, 308, 320, 8, 218, 320, 279, 289, 320:\n   ...     pep = peps[n]\n   >>> print(sorted(peps.keys()))\n   [218, 279, 289, 320]\n```\n\n## Add FIFO and MRU Cache Implementations\n\n```python\nfrom cachetools import FIFOCache, MRUCache\n\n# Example usage (conceptual)\nfifo_cache = FIFOCache(maxsize=100)\n# ... add items ...\n\nmru_cache = MRUCache(maxsize=100)\n# ... add items ...\n```\n\n## Caching Multiple Methods with Distinct Keys\n\n```python\nfrom cachetools.keys import methodkey\nfrom functools import partial\nfrom cachetools import LRUCache, cachedmethod\nimport urllib.request\n\nclass CachedReferences:\n\n    def __init__(self, cachesize):\n        self.cache = LRUCache(maxsize=cachesize)\n\n    @cachedmethod(lambda self: self.cache, key=partial(methodkey, method='pep'))\n    def get_pep(self, num):\n        \"\"\"Retrieve text of a Python Enhancement Proposal\"\"\"\n        url = 'http://www.python.org/dev/peps/pep-%04d/' % num\n        with urllib.request.urlopen(url) as s:\n            return s.read()\n\n    @cachedmethod(lambda self: self.cache, key=partial(methodkey, method='rfc'))\n    def get_rfc(self, num):\n        \"\"\"Retrieve text of an IETF Request for Comments\"\"\"\n        url = 'https://tools.ietf.org/rfc/rfc%d.txt' % num\n        with urllib.request.urlopen(url) as s:\n            return s.read()\n\ndocs = CachedReferences(cachesize=100)\nprint(\"PEP #20: %s\" % docs.get_pep(20))\nprint(\"RFC #20: %s\" % docs.get_rfc(20))\nassert len(docs.cache) == 2\n```\n\n## Cache Statistics Clearing\n\n```python\nfrom cachetools import LRUCache\n\ncache = LRUCache(maxsize=10)\ncache['a'] = 1\ncache.update_stats('a', 1)\n\nprint(cache.currsize, cache.hits, cache.misses)\n# Output might show non-zero hits/misses\n\ncache.clear_cache()\nprint(cache.currsize, cache.hits, cache.misses)\n# Output should show zero hits/misses\n```\n\n## Decorator Improvements for Race Conditions\n\n```python\nfrom cachetools import cached\n\n# Example usage (conceptual)\n@cached()\ndef my_function(arg1, arg2):\n    # ... function logic ...\n    pass\n```\n\n## cachetools Cache Implementations\n\n```APIDOC\nCache(maxsize, getsizeof=None)\n  This class discards arbitrary items using :meth:`popitem` to make space when necessary. Derived classes may override :meth:`popitem` to implement specific caching strategies. If a subclass has to keep track of item access, insertion or deletion, it may additionally need to override :meth:`__getitem__`, :meth:`__setitem__` and :meth:`__delitem__`.\n  Members:\n    currsize: Current number of items in the cache.\n    getsizeof: Function to retrieve the size of an item's value.\n    maxsize: Maximum number of items the cache can hold.\n```\n\n## cachetools Cache Implementations\n\n```APIDOC\nFIFOCache(maxsize, getsizeof=None)\n  This class evicts items in the order they were added to make space when necessary.\n  Members:\n    popitem: Removes and returns an arbitrary (key, value) pair from the cache.\n```\n\n## cachetools Cache Implementations\n\n```APIDOC\nLFUCache(maxsize, getsizeof=None)\n  This class counts how often an item is retrieved, and discards the items used least often to make space when necessary.\n  Members:\n    popitem: Removes and returns an arbitrary (key, value) pair from the cache.\n```\n\n## cachetools Cache Implementations\n\n```APIDOC\nLRUCache(maxsize, getsizeof=None)\n  This class discards the least recently used items first to make space when necessary.\n  Members:\n    popitem: Removes and returns an arbitrary (key, value) pair from the cache.\n```\n\n## cachetools Cache Implementations\n\n```APIDOC\nRRCache(maxsize, choice=random.choice, getsizeof=None)\n  This class randomly selects candidate items and discards them to make space when necessary. By default, items are selected from the list of cache keys using :func:`random.choice`. The optional argument `choice` may specify an alternative function that returns an arbitrary element from a non-empty sequence.\n  Members:\n    choice: Function used to select an item to discard.\n    popitem: Removes and returns an arbitrary (key, value) pair from the cache.\n```\n\n## cachetools Cache Implementations\n\n```APIDOC\nTTLCache(maxsize, ttl, timer=time.monotonic, getsizeof=None)\n  This class associates a time-to-live value with each item. Items that expire because they have exceeded their time-to-live will be no longer accessible, and will be removed eventually. If no expired items are there to remove, the least recently used items will be discarded first to make space when necessary. By default, the time-to-live is specified in seconds and :func:`time.monotonic` is used to retrieve the current time.\n  Members:\n    popitem: Removes and returns an arbitrary (key, value) pair from the cache.\n    timer: Function used to retrieve the current time.\n    ttl: Time-to-live value for items in seconds.\n```\n\n## TTLCache Example\n\n```python\ncache = TTLCache(maxsize=10, ttl=60)\n```\n\n## Caching Exceptions with a Wrapper\n\n```python\nfrom cachetools import cached, LRUCache\nimport urllib.request\nimport urllib.error\n\n@cached(cache=LRUCache(maxsize=10), info=True)\ndef _get_pep_wrapped(num):\n    url = \"http://www.python.org/dev/peps/pep-%04d/\" % num\n    try:\n        with urllib.request.urlopen(url) as s:\n            return s.read()\n    except urllib.error.HTTPError as e:\n        # note that only HTTPError instances are cached\n        return e\n\ndef get_pep(num):\n    \"\"\"Retrieve text of a Python Enhancement Proposal\"\"\"\n\n    res = _get_pep_wrapped(num)\n    if isinstance(res, Exception):\n        raise res\n    else:\n        return res\n\ntry:\n    get_pep(100_000_000)\nexcept Exception as e:\n    print(e, \"-\", _get_pep_wrapped.cache_info())\n\ntry:\n    get_pep(100_000_000)\nexcept Exception as e:\n    print(e, \"-\", _get_pep_wrapped.cache_info())\n```\n\n## @cached Decorator Documentation\n\n```APIDOC\n.. decorator:: cached(cache, key=cachetools.keys.hashkey, lock=None, condition=None, info=False)\n\n   Decorator to wrap a function with a memoizing callable that saves\n   results in a cache.\n\n   The `cache` argument specifies a cache object to store previous\n   function arguments and return values.  Note that `cache` need not\n   be an instance of the cache implementations provided by the\n   :mod:`cachetools` module.  :func:`cached` will work with any\n   mutable mapping type, including plain :class:`dict` and\n   :class:`weakref.WeakValueDictionary`.\n\n   `key` specifies a function that will be called with the same\n   positional and keyword arguments as the wrapped function itself,\n   and which has to return a suitable cache key.  Since caches are\n   mappings, the object returned by `key` must be hashable.  The\n   default is to call :func:`cachetools.keys.hashkey`.\n\n   If `lock` is not :const:`None`, it must specify an object\n   implementing the `context manager`_ protocol.  Any access to the\n   cache will then be nested in a ``with lock:`` statement.  This can\n   be used for synchronizing thread access to the cache by providing a\n   :class:`threading.Lock` or :class:`threading.RLock` instance,\n   for example.\n\n   .. note::\n\n      The `lock` context manager is used only to guard access to the\n      cache object.  The underlying wrapped function will be called\n      outside the `with` statement to allow concurrent execution, and\n      therefore must be `thread-safe`_ by itself.\n\n   If `condition` is not :const:`None`, it must specify a `condition\n   variable`_, i.e. an object providing :func:`wait()`,\n   :func:`wait_for()`, :func:`notify()` and :func:`notify_all()`\n   methods as defined by :class:`threading.Condition`.  Using a\n   `condition` variable will prevent concurrent execution of the\n   wrapped function with *identical* parameters, or cache keys.\n   Instead, a calling thread will check if an identical function call\n   is already executing, and will then :func:`wait()` for the pending\n   call to finish.  The executing thread will :func:`notify()` any\n   waiting threads as soon as the function completes, which will then\n   return the cached function result.\n\n   .. note::\n\n      Although providing a `lock` alone is generally sufficient to\n      make :func:`cached` `thread-safe`_, it may still be subject to\n      `cache stampede`_ issues under high load, depending on your\n      actual use case.  Providing a `condition` variable will mitigate\n      these situations, but will inflict some performance penalty.\n   \n   If no separate `lock` parameter is provided, `condition` must also\n   implement the `context manager`_ protocol, and will also be used to\n   guard access to the cache.\n\n   The decorator's `cache`, `key`, `lock` and `condition` parameters\n   are also available as :attr:`cache`, :attr:`cache_key`,\n   :attr:`cache_lock` and :attr:`cache_condition` attributes of the\n   memoizing wrapper function.  These can be used for clearing the\n   cache or invalidating individual cache items, for example.\n\n   .. testcode::\n\n      from threading import Lock\n\n      # 640K should be enough for anyone...\n      @cached(cache=LRUCache(maxsize=640*1024, getsizeof=len), lock=Lock())\n      def get_pep(num):\n          'Retrieve text of a Python Enhancement Proposal'\n          url = 'http://www.python.org/dev/peps/pep-%04d/' % num\n          with urllib.request.urlopen(url) as s:\n              return s.read()\n\n      # make sure access to cache is synchronized\n      with get_pep.cache_lock:\n          get_pep.cache.clear()\n\n      # always use the key function for accessing cache items\n      with get_pep.cache_lock:\n          get_pep.cache.pop(get_pep.cache_key(42), None)\n\n   For the common use case of clearing or invalidating the cache, the\n```",
    "library": "cachetools",
    "topic": "overview",
    "source": "fuzzy_match"
  },
  "source": "fuzzy_match",
  "saved_at": "2026-02-06T14:50:47.294002"
}