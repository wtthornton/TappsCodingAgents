# PRD: TappsCodingAgents Performance Insight Dashboard

**Version:** 1.0
**Author:** TappsCodingAgents Team
**Status:** DRAFT - Awaiting Review
**Date:** 2026-02-06

---

## 1. Problem Statement

TappsCodingAgents collects extensive metrics across agents, experts, cache, RAG, quality gates, workflows, and adaptive learning — but there is **no unified, visual way** to see how well the framework is performing when used by a project. Operators must run multiple CLI commands (`health overview`, `health usage agents`, etc.) and manually correlate JSONL/JSON/YAML files scattered across `.tapps-agents/`.

**We need a single interactive HTML page** that a developer can open from within their project to get full insight into what is working, what is not, and where to improve.

---

## 2. Goals

| # | Goal | Success Metric |
|---|------|---------------|
| G1 | Unified visibility into all tapps-agents subsystems | Single page covers agents, experts, cache, RAG, quality, workflows, learning |
| G2 | Local-only, zero-dependency | Opens in any browser, no server needed, no external CDN/API calls |
| G3 | Actionable insight | Each section surfaces "what's broken" alongside "what's healthy" |
| G4 | Project-scoped | Dashboard reads from `.tapps-agents/` of the current project only |
| G5 | Simple tech | Single self-contained HTML file with inline CSS/JS — no build step |

---

## 3. Non-Goals

- Real-time live-updating (websocket/polling) — this is a snapshot report
- Multi-project aggregation — scoped to one project at a time
- Authentication/authorization — local file, no security needed
- Persistent hosting — not a web app; generated and opened locally
- External dependencies (React, D3, CDN links) — everything inline

---

## 4. Architecture

### 4.1 Generation Flow

```
tapps-agents dashboard generate
        │
        ▼
┌─────────────────────────┐
│  DashboardGenerator     │
│  (Python, new module)   │
│                         │
│  1. Collect all metrics │
│  2. Build JSON payload  │
│  3. Inject into HTML    │
│  4. Write dashboard.html│
│  5. Open in browser     │
└─────────────────────────┘
        │
        ▼
  .tapps-agents/dashboard/
  └── dashboard.html  (self-contained, ~single file)
```

### 4.2 Data Collection

The generator will use existing Python APIs (no new data collection):

| Data Source | API/File | Dashboard Section |
|-------------|----------|-------------------|
| `AnalyticsDashboard.get_dashboard_data()` | System metrics, agent perf, workflow perf | Overview, Agents, Workflows |
| `HealthMetricsCollector.get_summary()` | Health check results | Health Ring |
| `HealthMetricsCollector.get_trends()` | Historical health scores | Health Trends |
| `ExecutionMetricsCollector.get_metrics()` | Execution records | Executions Timeline |
| `ExpertPerformanceTracker.get_all_performance()` | Expert stats | Expert Leaderboard |
| `BusinessMetricsCollector.collect_metrics()` | Adoption, effectiveness, ROI | Business Impact |
| `ConfidenceMetricsCollector` | Expert confidence history | Confidence Heatmap |
| `Analytics.get_cache_metrics()` | Context7 cache stats | Cache Health |
| `CacheStructure` metadata | Per-library cache entries | Cache Breakdown |
| `WorkflowEventLog` | Workflow event history | Event Stream |
| `EpicStateManager` | Epic/story state | Epic Progress |
| Quality gate scores from execution metrics | Per-execution gate results | Quality Gates |
| `.tapps-agents/learning/` | Learning outcomes | Learning Trends |

### 4.3 Tech Stack

- **Generator:** Python module (`tapps_agents/dashboard/generator.py`)
- **Output:** Single self-contained HTML file
- **Charts:** Inline SVG generated by Python (bar charts, sparklines, ring gauges) — no JS charting library
- **Interactivity:** Vanilla JS for tab switching, tooltips, expand/collapse, sorting, filtering
- **Styling:** Inline CSS, dark theme (matches developer tooling aesthetic)
- **Data:** JSON blob embedded in a `<script>` tag inside the HTML

---

## 5. Dashboard Sections

### 5.1 Header & Overview Strip

A top bar showing at-a-glance project health:

| Element | Source | Visual |
|---------|--------|--------|
| **Overall Health Score** | `HealthMetricsCollector.get_summary()` | Ring gauge (0-100), color-coded |
| **Project Name** | `.tapps-agents/config.yaml` or cwd basename | Text |
| **Generated At** | Timestamp | Text |
| **Workflows Today** | `AnalyticsDashboard` completed + failed today | Number pill |
| **Success Rate (30d)** | Workflow success % over 30 days | Number pill, color-coded |
| **Avg Quality Score** | Mean of recent quality gate scores | Number pill |
| **Cache Hit Rate** | Context7 cache hits / (hits + misses) | Number pill |
| **Active Experts** | Count of experts with consultations in last 30d | Number pill |

### 5.2 Agent Performance (Tab: "Agents")

**Purpose:** Show how each of the 14 workflow agents is performing.

| Element | Visual |
|---------|--------|
| **Agent Table** | Sortable table: Agent Name, Executions, Success Rate, Avg Duration, Last Run, Trend Sparkline |
| **Agent Detail (on click/expand)** | Per-agent: execution count over time (bar chart), failure reasons, avg duration trend, quality gate pass rate |
| **Worst Performers** | Callout box highlighting agents with <80% success rate or degrading trends |
| **Unused Agents** | List of agents with 0 executions (indicates potential adoption gap) |

**Data:** `AnalyticsDashboard.get_agent_performance()` for each agent

### 5.3 Expert System (Tab: "Experts")

**Purpose:** Show expert consultation effectiveness and ROI.

| Element | Visual |
|---------|--------|
| **Expert Leaderboard** | Table: Expert ID, Consultations, Avg Confidence, First-Pass Success Rate, Quality Impact, Domains |
| **Confidence Distribution** | Horizontal bar chart showing confidence ranges (0-0.5, 0.5-0.7, 0.7-0.85, 0.85-1.0) with counts |
| **Domain Coverage Map** | Tag cloud or grid showing which domains have expert coverage and consultation frequency |
| **Low Confidence Alerts** | List of recent consultations where confidence < threshold |
| **Expert ROI** | Estimated time saved, bugs prevented, cost per consultation |
| **Auto-Generated vs. Defined** | Pie split showing built-in vs. auto-generated vs. project-defined experts |

**Data:** `ExpertPerformanceTracker`, `BusinessMetricsCollector`, `ConfidenceMetricsCollector`

### 5.4 Cache & RAG (Tab: "Cache & RAG")

**Purpose:** Show Context7 cache effectiveness and RAG quality.

| Element | Visual |
|---------|--------|
| **Cache Overview** | Total entries, total size, total tokens, total libraries |
| **Hit Rate Gauge** | Ring gauge showing cache hit rate % |
| **Library Breakdown** | Table: Library Name, Topics Cached, Cache Hits, Tokens, Size, Last Accessed, Freshness (expired?) |
| **Cache Miss Hotspots** | Top 10 most-missed lookups (what's being requested but not cached) |
| **RAG Quality Score** | From business metrics `rag_quality_score` |
| **Skill Usage** | Table: Skill Name, Lookups, Cache Hits, API Calls, Avg Response Time |
| **Cache Freshness** | Visual indicator per library: fresh (green), aging (yellow), expired (red) based on TTL |
| **Recommendations** | Auto-generated suggestions: "Library X has 0 hits — consider removing", "Library Y has high miss rate — consider pre-populating" |

**Data:** `Analytics.get_cache_metrics()`, `CacheStructure` metadata, skill usage JSON

### 5.5 Quality Gates (Tab: "Quality")

**Purpose:** Show code quality trends and gate pass/fail patterns.

| Element | Visual |
|---------|--------|
| **Gate Pass Rate** | Overall % of executions that passed quality gates |
| **Score Distribution** | Histogram of overall quality scores (buckets: 0-50, 50-60, 60-70, 70-75, 75-80, 80-90, 90-100) |
| **Dimension Breakdown** | Radar/spider chart (or stacked bar) showing avg scores for: Complexity, Security, Maintainability, Test Coverage, Performance, Structure, DevEx |
| **Score Trend** | Line sparkline showing average quality score over last 30 days |
| **Recent Failures** | Table of recent gate failures: Workflow, Step, Score, Failing Dimension, Date |
| **Loopback Rate** | % of workflows that required quality loopback (re-review) |

**Data:** Execution metrics (gate_pass field), quality_scores from workflow events

### 5.6 Workflows (Tab: "Workflows")

**Purpose:** Show workflow execution patterns and bottlenecks.

| Element | Visual |
|---------|--------|
| **Workflow Summary** | Table: Workflow Name/Preset, Executions, Success Rate, Avg Duration, Avg Steps, Last Run |
| **Preset Distribution** | Bar chart showing count of minimal/standard/comprehensive/full-sdlc executions |
| **Duration Trend** | Sparkline per workflow type showing duration over time |
| **Step Failure Heatmap** | Grid showing which steps fail most often across workflows |
| **Checkpoint Efficiency** | Stats on checkpoint activations: early terminations, workflow switches, tokens saved |
| **Active/Recent Epics** | Cards showing epic progress: story completion %, current story, blockers |

**Data:** `AnalyticsDashboard.get_workflow_performance()`, execution metrics, epic state

### 5.7 Adaptive Learning (Tab: "Learning")

**Purpose:** Show how the system is learning and improving over time.

| Element | Visual |
|---------|--------|
| **Learning Trend** | Line chart showing first-pass success rate over time |
| **Expert Weight Adjustments** | Table showing expert voting weight changes: Expert, Old Weight, New Weight, Reason |
| **Auto-Generated Experts** | Timeline of when new experts were auto-created, with domains |
| **Scoring Weight Evolution** | Table or chart showing how quality scoring weights have been adjusted |
| **Outcome Tracking** | Success/failure/partial counts for recent tasks, with improvement delta |
| **Knowledge Base Growth** | Total KB entries over time |

**Data:** `.tapps-agents/learning/` files, expert performance tracker

### 5.8 Health Checks (Tab: "Health")

**Purpose:** Detailed health status per subsystem.

| Element | Visual |
|---------|--------|
| **Health Grid** | Card per check: Environment, Automation, Execution, Cache, Knowledge, Outcomes — each with status badge (healthy/degraded/unhealthy), score, and details |
| **Remediation Actions** | For any degraded/unhealthy checks, show actionable remediation steps |
| **Health History** | Sparkline per check showing score trend over last 30 days |
| **Overall Trend** | Combined health score trend line |

**Data:** `HealthMetricsCollector.get_summary()`, `get_trends()`

### 5.9 Event Stream (Collapsible Footer)

**Purpose:** Raw event log for debugging and auditing.

| Element | Visual |
|---------|--------|
| **Recent Events** | Scrollable table: Timestamp, Event Type, Workflow, Step, Status, Details (expandable) |
| **Event Type Filter** | Checkbox filters for event types |
| **Event Count by Type** | Small bar chart |

**Data:** `WorkflowEventLog`, event files in `.tapps-agents/events/`

---

## 6. CLI Integration

### 6.1 New Command

```bash
# Generate and open dashboard
tapps-agents dashboard

# Generate only (don't open browser)
tapps-agents dashboard --no-open

# Specify output path
tapps-agents dashboard --output ./my-dashboard.html

# Specify time range
tapps-agents dashboard --days 30

# Generate with verbose data (include raw event stream)
tapps-agents dashboard --verbose
```

### 6.2 Simple Mode Integration

```
@simple-mode *dashboard          # Generate and open
tapps-agents simple-mode dashboard  # CLI equivalent
```

### 6.3 Output Location

Default: `.tapps-agents/dashboard/dashboard.html`

The file is added to `.gitignore` (project-specific, not committed).

---

## 7. Visual Design

### 7.1 Theme

- **Dark theme** — charcoal background (#1a1a2e), card surfaces (#16213e), accent blue (#0f3460), highlight cyan (#53d8fb)
- **Color semantics:** Green (#00b894) = healthy/pass, Yellow (#fdcb6e) = warning/degraded, Red (#ff6b6b) = failure/unhealthy, Blue (#74b9ff) = info/neutral
- **Typography:** System monospace font stack (`ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, monospace`)
- **Layout:** Single-page with tab navigation; responsive but optimized for desktop (1200px+)

### 7.2 Interaction Model

- **Tabs** for major sections (Agents, Experts, Cache & RAG, Quality, Workflows, Learning, Health)
- **Sortable tables** (click column header to sort)
- **Expandable rows** (click to see detail)
- **Tooltips** on hover for metrics with explanations
- **Collapse/expand** for secondary information
- **No external navigation** — everything on one page

### 7.3 Size Budget

Target: **< 500KB** for the complete HTML file (including embedded data). For projects with extensive history, the generator will cap data at 90 days and truncate event streams to last 500 events.

---

## 8. Module Structure

```
tapps_agents/dashboard/
├── __init__.py
├── generator.py          # Main orchestrator: collects data, renders HTML
├── data_collector.py     # Gathers data from all subsystems into unified dict
├── html_renderer.py      # Renders HTML string from data dict
├── svg_charts.py         # Pure-Python SVG chart generators (bar, ring, sparkline, radar)
└── templates/
    └── shell.html        # Base HTML template with CSS and JS placeholders
```

### 8.1 Key Classes

```python
class DashboardDataCollector:
    """Collects metrics from all subsystems into a unified JSON-serializable dict."""
    def __init__(self, project_root: Path, days: int = 30)
    def collect_all(self) -> dict
    def collect_health(self) -> dict
    def collect_agents(self) -> dict
    def collect_experts(self) -> dict
    def collect_cache(self) -> dict
    def collect_quality(self) -> dict
    def collect_workflows(self) -> dict
    def collect_learning(self) -> dict
    def collect_events(self, limit: int = 500) -> list

class SVGChartBuilder:
    """Pure-Python SVG chart generation — no dependencies."""
    def ring_gauge(self, value: float, max_val: float, ...) -> str
    def bar_chart(self, labels: list, values: list, ...) -> str
    def sparkline(self, values: list, ...) -> str
    def radar_chart(self, dimensions: dict, ...) -> str
    def histogram(self, values: list, buckets: int, ...) -> str

class HTMLRenderer:
    """Assembles final HTML from data + charts."""
    def render(self, data: dict) -> str

class DashboardGenerator:
    """CLI entry point: collect -> render -> write -> open."""
    def generate(self, output_path: Path, days: int, open_browser: bool, verbose: bool)
```

---

## 9. Data Schema (Embedded JSON)

The HTML file will contain a `<script id="dashboard-data" type="application/json">` block with this structure:

```json
{
  "meta": {
    "project_name": "my-project",
    "generated_at": "2026-02-06T14:30:00Z",
    "days": 30,
    "tapps_agents_version": "3.6.3"
  },
  "health": {
    "overall_score": 85,
    "checks": [ { "name": "...", "status": "...", "score": 0, "details": {}, "remediation": [] } ]
  },
  "agents": {
    "summary": { "total": 14, "active": 8, "avg_success_rate": 92.5 },
    "agents": [ { "name": "...", "executions": 0, "success_rate": 0, "avg_duration_ms": 0, "trend": [] } ]
  },
  "experts": {
    "summary": { "total": 12, "active": 8, "avg_confidence": 0.82 },
    "experts": [ { "id": "...", "consultations": 0, "avg_confidence": 0, "first_pass_rate": 0, "domains": [] } ],
    "confidence_distribution": { "low": 0, "medium": 0, "high": 0, "very_high": 0 },
    "roi": { "time_saved_hours": 0, "bugs_prevented": 0, "roi_percentage": 0 }
  },
  "cache": {
    "summary": { "total_entries": 0, "hit_rate": 0, "total_tokens": 0, "total_size_bytes": 0 },
    "libraries": [ { "name": "...", "topics": 0, "hits": 0, "tokens": 0, "fresh": true } ],
    "skill_usage": [ { "skill": "...", "lookups": 0, "hits": 0, "misses": 0 } ],
    "rag_quality_score": 0
  },
  "quality": {
    "gate_pass_rate": 0,
    "avg_score": 0,
    "dimensions": { "complexity": 0, "security": 0, "maintainability": 0, "test_coverage": 0, "performance": 0, "structure": 0, "devex": 0 },
    "score_trend": [],
    "recent_failures": []
  },
  "workflows": {
    "summary": { "total": 0, "success_rate": 0, "avg_duration_ms": 0 },
    "workflows": [ { "name": "...", "executions": 0, "success_rate": 0, "avg_duration_ms": 0 } ],
    "preset_distribution": { "minimal": 0, "standard": 0, "comprehensive": 0, "full_sdlc": 0 },
    "epics": []
  },
  "learning": {
    "first_pass_trend": [],
    "auto_generated_experts": [],
    "weight_adjustments": [],
    "kb_growth": []
  },
  "events": []
}
```

---

## 10. Recommendations Engine

The dashboard will include an auto-generated **"Recommendations"** panel at the top of each tab. The generator analyzes the data and produces actionable suggestions:

| Condition | Recommendation |
|-----------|---------------|
| Agent success rate < 80% | "Agent {name} has a {rate}% success rate. Review recent failures for patterns." |
| Expert confidence < 0.6 avg | "Expert {id} has low confidence ({val}). Consider enriching its knowledge base." |
| Cache hit rate < 50% | "Cache hit rate is {rate}%. Run `tapps-agents init` to pre-populate cache." |
| Quality gate failures > 30% | "Quality gates are failing {rate}% of the time. Review scoring thresholds." |
| Unused agents (0 executions) | "{count} agents have never been used. Consider workflow adoption training." |
| Cache entries expired > 50% | "{count} cache entries are expired. Run `tapps-agents cache refresh`." |
| No expert consultations in 7d | "No expert consultations in the last 7 days. Ensure expert system is enabled." |
| Workflow avg duration increasing | "Workflow duration is trending up. Check for bottlenecks in step {name}." |

---

## 11. Testing Strategy

| Test Type | Scope | Approach |
|-----------|-------|----------|
| Unit tests | `data_collector.py` | Mock all subsystem APIs, verify collected data shape |
| Unit tests | `svg_charts.py` | Verify SVG output contains expected elements, valid XML |
| Unit tests | `html_renderer.py` | Verify HTML output contains required sections, valid structure |
| Integration test | `generator.py` | Generate dashboard from fixture data, verify file created and parseable |
| Snapshot test | Full pipeline | Generate from known fixture, compare against golden file |
| CLI test | `tapps-agents dashboard` | Verify command registers, runs, produces output file |

---

## 12. Rollout Plan

### Phase 1: Core Dashboard (MVP)
- DashboardDataCollector with all subsystems
- SVG chart library (ring gauge, bar chart, sparkline)
- HTML renderer with all 8 tabs
- CLI command `tapps-agents dashboard`
- Unit tests for data collection and charts

### Phase 2: Polish
- Recommendations engine
- Radar chart for quality dimensions
- Expand/collapse detail rows
- Sorting on all tables
- Tooltip explanations

### Phase 3: Simple Mode Integration
- `@simple-mode *dashboard` skill
- Auto-suggest dashboard after workflow completion (optional hook)

---

## 13. Open Questions

| # | Question | Default If Unresolved |
|---|----------|----------------------|
| Q1 | Should the dashboard auto-open after every workflow? | No — explicit command only |
| Q2 | Should we support a `--watch` mode that regenerates on file change? | No — out of scope for v1 |
| Q3 | Should the dashboard include a "compare" mode (this week vs last week)? | Defer to Phase 2 |
| Q4 | Maximum data retention period for the dashboard? | 90 days |

---

## 14. Success Criteria

| Criteria | Target |
|----------|--------|
| Single command to generate and view | `tapps-agents dashboard` opens browser in < 5 seconds |
| File size | < 500KB for 30 days of data |
| Zero external dependencies | No CDN, no npm, no build step |
| Coverage of all subsystems | All 8 tabs populated with real data |
| Actionable recommendations | At least 3 recommendations generated for any non-trivial project |
| Test coverage | >= 80% for new module |

---

## Appendix A: Mockup (ASCII)

```
┌──────────────────────────────────────────────────────────────────────────┐
│  TappsCodingAgents Dashboard           my-project    Feb 6, 2026 14:30  │
├──────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   ┌─────┐   Workflows    Success     Avg Quality   Cache Hit   Active   │
│   │ 85  │    Today: 12   Rate: 92%   Score: 78     Rate: 67%  Experts:8 │
│   │/100 │                                                                │
│   └─────┘                                                                │
│                                                                          │
│ ┌─────────┬─────────┬───────────┬─────────┬──────────┬─────────┬───────┐│
│ │ Agents  │ Experts │ Cache/RAG │ Quality │Workflows │Learning │Health ││
│ ├─────────┴─────────┴───────────┴─────────┴──────────┴─────────┴───────┤│
│ │                                                                       ││
│ │  ┌─ Recommendations ──────────────────────────────────────────────┐   ││
│ │  │ ! Agent "debugger" has 65% success rate — review failures      │   ││
│ │  │ ! 3 cache entries expired — run refresh                        │   ││
│ │  └────────────────────────────────────────────────────────────────┘   ││
│ │                                                                       ││
│ │  Agent           Executions  Success%  Avg Duration  Last Run  Trend  ││
│ │  ─────────────── ────────── ────────── ──────────── ──────── ──────  ││
│ │  implementer          45      95.6%      12.3s       2h ago   ▁▃▅▇   ││
│ │  reviewer             38      92.1%       8.7s       3h ago   ▃▅▅▇   ││
│ │  tester               32      87.5%      15.1s       1h ago   ▅▃▃▅   ││
│ │  debugger             12      66.7%      22.4s       1d ago   ▇▅▃▁   ││
│ │  ...                                                                  ││
│ │                                                                       ││
│ │  ┌─ Worst Performers ─────────────────────────────────────────────┐   ││
│ │  │ debugger: 66.7% success (8/12) — common error: "timeout"       │   ││
│ │  └────────────────────────────────────────────────────────────────┘   ││
│ │                                                                       ││
│ └───────────────────────────────────────────────────────────────────────┘│
│                                                                          │
│ ▶ Event Stream (click to expand)                                        │
└──────────────────────────────────────────────────────────────────────────┘
```

---

**End of PRD**
