# Story 17.2: Add Real Agent Behavior Tests

<!-- Source: implementation/cursor/EPIC_17_Unit_Test_Mock_Reduction.md -->
<!-- Context: Reduce mocking in ReviewerAgent tests and test actual agent execution paths -->

## Status

Completed (2025-01-15)

## Story

**As a** developer,
**I want** agent tests to validate real agent behavior and execution paths,
**so that** we catch integration issues and validate that agents work correctly end-to-end, not just that mocked methods are called.

## Acceptance Criteria

1. Mocking in ReviewerAgent tests is reduced, replacing mocks with real implementations where feasible.
2. Actual CodeScorer behavior is tested, not just mocked results.
3. Real agent execution paths are validated (agent initialization, command processing, result generation).
4. Error propagation through real agent code is tested (errors from dependencies propagate correctly).
5. Test execution time remains reasonable (use fakes for slow operations, not mocks).
6. Tests remain isolated and don't affect each other (use test data isolation).

## Tasks / Subtasks

- [ ] Task 1: Analyze current ReviewerAgent test mocking (AC: 1)
  - [ ] Review `tests/unit/agents/test_reviewer_agent.py` for mock usage
  - [ ] Identify which dependencies can use real implementations
  - [ ] Identify which dependencies need fakes vs real implementations

- [ ] Task 2: Replace mocked CodeScorer with real implementation (AC: 2)
  - [ ] Update ReviewerAgent tests to use real CodeScorer instances
  - [ ] Test actual scoring logic and calculations
  - [ ] Validate scoring results are correct, not just that methods were called

- [ ] Task 3: Test real agent execution paths (AC: 3)
  - [ ] Test agent initialization with real dependencies
  - [ ] Test command processing with real agent code
  - [ ] Test result generation and formatting
  - [ ] Validate agent lifecycle (setup → execute → cleanup)

- [ ] Task 4: Test error propagation through real agent code (AC: 4)
  - [ ] Test errors from MAL propagate correctly
  - [ ] Test errors from CodeScorer propagate correctly
  - [ ] Test errors from cache propagate correctly
  - [ ] Validate error handling and reporting

- [ ] Task 5: Create fakes for complex dependencies (AC: 5)
  - [ ] Create fake implementations for slow operations (e.g., LLM calls)
  - [ ] Use fakes instead of mocks for complex dependencies
  - [ ] Ensure fakes implement real behavior, not just method signatures

- [ ] Task 6: Ensure test isolation (AC: 6)
  - [ ] Use test data isolation instead of mocks
  - [ ] Ensure tests don't affect each other
  - [ ] Use fixtures for test setup and cleanup

## Dev Notes

### Existing System Context

- ReviewerAgent exists in `tapps_agents/agents/reviewer/agent.py`:
  - Uses CodeScorer for code quality scoring
  - Uses MAL for LLM interactions
  - Uses cache for storing results
  - Current tests heavily mock these dependencies
- CodeScorer exists in `tapps_agents/quality/code_scorer.py`:
  - Implements five-metric scoring system
  - Can be used with real implementations
- Current test files:
  - `tests/unit/agents/test_reviewer_agent.py` - Unit tests with heavy mocking
  - `tests/integration/test_reviewer_agent.py` - Integration tests (may have real behavior)
  - `tests/integration/test_reviewer_agent_real.py` - Real integration tests (opt-in)
- Test infrastructure:
  - Uses pytest with fixtures
  - Has test data and fixtures in `tests/conftest.py`
  - Uses `unittest.mock` extensively

### Integration Approach

- Replace mocks with real implementations where feasible (CodeScorer, cache)
- Use fakes for slow operations (LLM calls via MAL) - create fast fake MAL that returns deterministic results
- Test real agent execution paths: initialization → command processing → result generation
- Use test data isolation: different test files, cache directories, etc.
- Keep integration tests separate from unit tests (use pytest markers)

### Risk Assessment

- **Risk**: Real implementations may require external dependencies or slow down tests
- **Mitigation**: Use fakes for slow operations, test fixtures for external dependencies
- **Risk**: Tests may become more complex
- **Mitigation**: Create reusable fixtures and helper functions
- **Risk**: Real behavior may expose bugs in production code
- **Mitigation**: This is the goal - catch bugs early

### Rollback Plan

- Can revert to mocks if real implementations cause issues
- Keep existing mocked tests as backup (rename or move to separate file)
- No impact on production code

### Testing

- Test file location: `tests/unit/agents/test_reviewer_agent.py`
- Test standards: pytest, fixtures for isolation, real implementations where feasible
- Testing frameworks: pytest, fakes for slow operations
- Specific requirements:
  - Use pytest markers for slow integration tests
  - Ensure test isolation through fixtures and test data
  - Validate real agent behavior, not just method calls
  - Test error propagation through real code paths

## Change Log

| Date       | Version | Description                       | Author      |
| ---------- | ------- | --------------------------------- | ----------- |
| 2025-01-15 | 0.1     | Initial draft for Epic 17.2       | bmad-master |

## Dev Agent Record

### Agent Model Used

_TBD_

### Debug Log References

_TBD_

### Completion Notes List

- _TBD_

### File List

- _TBD_

## QA Results

_TBD_

