# Story 17.1: Reduce Mocking in MAL Tests

<!-- Source: implementation/cursor/EPIC_17_Unit_Test_Mock_Reduction.md -->
<!-- Context: Replace HTTP client mocks with test server or real httpx with test fixtures to validate actual network behavior -->

## Status

Completed (2025-01-15)

## Story

**As a** developer,
**I want** MAL tests to use real HTTP implementations or test servers instead of heavy mocking,
**so that** we validate actual network behavior, timeout handling, error responses, and fallback logic with real provider behavior.

## Acceptance Criteria

1. HTTP client mocks in MAL tests are replaced with test servers (e.g., `httpx.ASGITransport` with test app) or real httpx with test fixtures where feasible.
2. Tests validate actual network behavior including:
   - Real HTTP request/response cycles
   - Timeout handling with actual timeout scenarios
   - Error response handling (4xx, 5xx status codes)
   - Network error scenarios (connection refused, DNS failures)
3. Real response parsing and error handling is tested, not just mocked method calls.
4. Fallback logic is tested with real provider behavior (e.g., Ollama → Anthropic → OpenAI fallback chain).
5. Test execution time remains reasonable (use test fixtures and fast test servers).
6. Tests remain isolated and don't affect each other (use test data isolation).

## Tasks / Subtasks

- [ ] Task 1: Set up test server infrastructure for MAL tests (AC: 1, 5)
  - [ ] Create pytest fixtures for test HTTP servers (using httpx.ASGITransport or similar)
  - [ ] Create fixtures for different provider endpoints (Ollama, Anthropic, OpenAI)
  - [ ] Ensure test servers are fast and isolated per test

- [ ] Task 2: Replace Ollama provider mocks with test server (AC: 1, 2)
  - [ ] Update `tests/unit/core/test_mal.py::TestMALOllamaProvider` to use test server
  - [ ] Test real HTTP request/response cycles
  - [ ] Test timeout handling with actual timeouts
  - [ ] Test error responses (4xx, 5xx)

- [ ] Task 3: Replace cloud provider mocks with test server (AC: 1, 2)
  - [ ] Update `tests/unit/core/test_mal_cloud.py::TestCloudMAL` to use test server
  - [ ] Test Anthropic API with real HTTP behavior
  - [ ] Test OpenAI API with real HTTP behavior
  - [ ] Test network error scenarios

- [ ] Task 4: Test real response parsing and error handling (AC: 3)
  - [ ] Validate actual JSON parsing from real responses
  - [ ] Test error response parsing (API error formats)
  - [ ] Test malformed response handling

- [ ] Task 5: Test fallback logic with real provider behavior (AC: 4)
  - [ ] Create integration-style tests for provider fallback chain
  - [ ] Test Ollama → Anthropic fallback with real behavior
  - [ ] Test Anthropic → OpenAI fallback with real behavior
  - [ ] Validate fallback triggers on actual failures

- [ ] Task 6: Ensure test isolation and performance (AC: 5, 6)
  - [ ] Verify tests don't affect each other
  - [ ] Mark slow integration tests appropriately (pytest markers)
  - [ ] Use test data isolation instead of mocks where possible

## Dev Notes

### Existing System Context

- MAL (Model Abstraction Layer) exists in `tapps_agents/core/mal.py`:
  - Supports multiple providers: Ollama, Anthropic, OpenAI
  - Uses `httpx.AsyncClient` for HTTP requests
  - Has timeout configuration and fallback logic
  - Current tests heavily mock `httpx.AsyncClient` and responses
- Current test files:
  - `tests/unit/core/test_mal.py` - Tests Ollama provider with mocked httpx
  - `tests/unit/core/test_mal_cloud.py` - Tests cloud providers with mocked httpx
  - `tests/integration/test_mal_real.py` - Integration tests with real providers (opt-in)
- Test infrastructure:
  - Uses pytest with async support
  - Has fixtures in `tests/conftest.py`
  - Uses `unittest.mock` extensively for HTTP mocking

### Integration Approach

- Use `httpx.ASGITransport` or `httpx.WSGITransport` with test ASGI/WSGI apps to create fast test servers
- Alternatively, use `httpx.MockTransport` for more control while still testing real httpx behavior
- Create pytest fixtures that provide test server URLs for each provider
- Keep test servers lightweight and fast (in-memory, no actual network)
- Use test data isolation (different ports/URLs per test) instead of mocks

### Risk Assessment

- **Risk**: Test servers may slow down test execution
- **Mitigation**: Use lightweight in-memory test servers, mark slow tests appropriately
- **Risk**: Real HTTP behavior may be flaky
- **Mitigation**: Use deterministic test servers, not actual external services
- **Risk**: Tests may become more complex
- **Mitigation**: Create reusable fixtures and helper functions

### Rollback Plan

- Can revert to mocks if test servers cause issues
- Keep existing mocked tests as backup (rename or move to separate file)
- No impact on production code

### Testing

- Test file location: `tests/unit/core/test_mal.py`, `tests/unit/core/test_mal_cloud.py`
- Test standards: pytest, async support, fixtures for isolation
- Testing frameworks: pytest, httpx for test servers
- Specific requirements:
  - Use pytest markers for slow integration tests
  - Ensure test isolation through fixtures
  - Validate real HTTP behavior, not just method calls

## Change Log

| Date       | Version | Description                       | Author      |
| ---------- | ------- | --------------------------------- | ----------- |
| 2025-01-15 | 0.1     | Initial draft for Epic 17.1       | bmad-master |

## Dev Agent Record

### Agent Model Used

_TBD_

### Debug Log References

_TBD_

### Completion Notes List

- _TBD_

### File List

- _TBD_

## QA Results

_TBD_

