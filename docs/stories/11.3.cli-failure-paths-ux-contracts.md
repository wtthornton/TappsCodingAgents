# Story 11.3: CLI Failure Paths + UX Contracts

<!-- Source: implementation/cursor/EPIC_11_E2E_CLI_Tests.md -->
<!-- Context: Implement E2E tests for CLI failure paths (missing file, missing workflow, invalid args, missing credentials) with UX contract validation -->

## Status

Draft

## Story

**As a** QA engineer and developer,
**I want** E2E tests for CLI failure paths that validate error handling, exit codes, and user-actionable error messages,
**so that** I have confidence that CLI commands handle errors gracefully and provide helpful feedback to users.

## Acceptance Criteria

1. E2E test exists for "missing file" error case:
   - Test: Execute `tapps-agents review <nonexistent-file>`
   - Test: Validate exit code is non-zero (failure)
   - Test: Validate error message indicates file not found
   - Test: Validate error message includes file path
   - Test: Validate error is printed to stderr (not stdout)
   - Test: Validate error message is user-actionable
2. E2E test exists for "missing workflow" error case:
   - Test: Execute `tapps-agents workflow start <nonexistent-workflow>`
   - Test: Validate exit code is non-zero (failure)
   - Test: Validate error message indicates workflow not found
   - Test: Validate error message is user-actionable (suggests available workflows)
   - Test: Validate error is printed to stderr
3. E2E test exists for "invalid arguments" error case:
   - Test: Execute `tapps-agents review` (missing required argument)
   - Test: Validate exit code is non-zero (failure)
   - Test: Validate error message indicates missing/invalid argument
   - Test: Validate error message is user-actionable (shows usage/help)
   - Test: Validate error is printed to stderr
4. E2E test exists for "missing credentials" error case (if applicable):
   - Test: Execute command that requires credentials without credentials
   - Test: Validate exit code is non-zero (failure) or appropriate skip behavior
   - Test: Validate error message indicates missing credentials
   - Test: Validate error message is user-actionable (shows how to set credentials)
   - Test: Validate error is printed to stderr
5. E2E test exists for "invalid file format" error case (if applicable):
   - Test: Execute `tapps-agents review <invalid-file>` (wrong file type, corrupted, etc.)
   - Test: Validate exit code is non-zero (failure)
   - Test: Validate error message indicates invalid file format
   - Test: Validate error message is user-actionable
   - Test: Validate error is printed to stderr
6. All tests use CLI harness from Story 11.1:
   - Use `run_cli_command()` or `capture_cli_output()` for command execution
   - Use `assert_cli_failure()` for failure validation
   - Use isolated project environments
7. All tests validate UX contracts (stable, non-brittle):
   - Exit code validation (non-zero for failures)
   - Error message presence (error message exists)
   - Error message location (stderr, not stdout)
   - User-actionable validation (error message is helpful)
   - Avoid over-constraining error message text (allow for minor wording changes)
8. All tests use isolated project environments:
   - Use E2E harness project templates
   - Each test uses its own temporary project directory
   - Clean state before each test
   - Cleanup after test completion
9. All tests include explicit timeouts and produce actionable failure artifacts:
   - Command-level timeouts
   - Failure artifacts include: stdout, stderr, exit code, command executed, project state
10. All tests are marked with `e2e_cli` marker.
11. All tests validate error message quality:
    - Error messages are clear and specific
    - Error messages include relevant context (file path, command, etc.)
    - Error messages suggest remediation when possible
    - Error messages avoid technical jargon when possible
12. Documentation exists for running CLI failure path tests.

## Tasks / Subtasks

- [ ] Task 1: Create test for "missing file" error (AC: 1, 6, 7, 8, 9, 10, 11)
  - [ ] Create `tests/e2e/cli/test_missing_file_error.py`
  - [ ] Use CLI harness to execute `tapps-agents review <nonexistent-file>`
  - [ ] Use isolated project
  - [ ] Validate exit code is non-zero
  - [ ] Validate error message indicates file not found
  - [ ] Validate error message includes file path
  - [ ] Validate error is in stderr
  - [ ] Validate error message is user-actionable
  - [ ] Mark with `e2e_cli`
  - [ ] Add timeouts and failure artifact capture

- [ ] Task 2: Create test for "missing workflow" error (AC: 2, 6, 7, 8, 9, 10, 11)
  - [ ] Create `tests/e2e/cli/test_missing_workflow_error.py`
  - [ ] Use CLI harness to execute `tapps-agents workflow start <nonexistent-workflow>`
  - [ ] Use isolated project
  - [ ] Validate exit code is non-zero
  - [ ] Validate error message indicates workflow not found
  - [ ] Validate error message suggests available workflows (if possible)
  - [ ] Validate error is in stderr
  - [ ] Validate error message is user-actionable
  - [ ] Mark with `e2e_cli`
  - [ ] Add timeouts and failure artifact capture

- [ ] Task 3: Create test for "invalid arguments" error (AC: 3, 6, 7, 8, 9, 10, 11)
  - [ ] Create `tests/e2e/cli/test_invalid_args_error.py`
  - [ ] Use CLI harness to execute `tapps-agents review` (missing required arg)
  - [ ] Use isolated project
  - [ ] Validate exit code is non-zero
  - [ ] Validate error message indicates missing/invalid argument
  - [ ] Validate error message shows usage/help (if possible)
  - [ ] Validate error is in stderr
  - [ ] Validate error message is user-actionable
  - [ ] Mark with `e2e_cli`
  - [ ] Add timeouts and failure artifact capture

- [ ] Task 4: Create test for "missing credentials" error (AC: 4, 6, 7, 8, 9, 10, 11)
  - [ ] Identify commands that require credentials
  - [ ] Create `tests/e2e/cli/test_missing_credentials_error.py`
  - [ ] Use CLI harness to execute command without credentials
  - [ ] Use isolated project (no credentials configured)
  - [ ] Validate exit code is non-zero or appropriate skip behavior
  - [ ] Validate error message indicates missing credentials
  - [ ] Validate error message shows how to set credentials (if possible)
  - [ ] Validate error is in stderr
  - [ ] Validate error message is user-actionable
  - [ ] Mark with `e2e_cli`
  - [ ] Add timeouts and failure artifact capture
  - [ ] If no commands require credentials, document as N/A

- [ ] Task 5: Create test for "invalid file format" error (AC: 5, 6, 7, 8, 9, 10, 11)
  - [ ] Check if CLI validates file formats
  - [ ] If applicable, create `tests/e2e/cli/test_invalid_file_format_error.py`
  - [ ] Use CLI harness to execute command with invalid file (wrong type, corrupted, etc.)
  - [ ] Use isolated project with invalid test file
  - [ ] Validate exit code is non-zero
  - [ ] Validate error message indicates invalid file format
  - [ ] Validate error is in stderr
  - [ ] Validate error message is user-actionable
  - [ ] Mark with `e2e_cli`
  - [ ] Add timeouts and failure artifact capture
  - [ ] If not applicable, document as N/A

- [ ] Task 6: Implement UX contract validation (AC: 7, 11)
  - [ ] Create UX contract validation utilities
  - [ ] Validate exit codes (non-zero for failures)
  - [ ] Validate error message presence
  - [ ] Validate error message location (stderr)
  - [ ] Validate user-actionable quality (clear, specific, suggests remediation)
  - [ ] Avoid over-constraining error message text
  - [ ] Provide clear validation error messages

- [ ] Task 7: Optimize test execution and reliability (AC: 9)
  - [ ] Review test execution time
  - [ ] Optimize slow tests (reduce fixture complexity)
  - [ ] Ensure command-level timeouts are appropriate
  - [ ] Validate failure artifact capture works correctly
  - [ ] Test artifact capture in failing scenarios

- [ ] Task 8: Documentation and validation (AC: 12)
  - [ ] Document CLI failure path test coverage in `tests/e2e/cli/README.md`
  - [ ] Document how to run CLI failure path tests locally
  - [ ] Document UX contract validation approach
  - [ ] Document error message quality standards
  - [ ] Document command-specific error cases
  - [ ] Verify all tests validate error handling correctly

## Dev Notes

### Existing System Context

- CLI commands:
  - `tapps_agents/cli.py` - CLI entry point with commands
  - Error handling: commands use `sys.exit(1)` for failures, print errors to stderr
  - Commands: `review`, `score`, `workflow`, `init`, `doctor`, etc.
- CLI harness (from Story 11.1):
  - `tests/e2e/fixtures/cli_runner.py` - CLI runner harness
  - `assert_cli_failure()` - failure validation utility
- E2E foundation (from Epic 8):
  - `tests/e2e/fixtures/e2e_harness.py` - E2E harness utilities
  - `tests/e2e/fixtures/project_templates.py` - project templates
  - `tests/e2e/conftest.py` - E2E fixtures
- Existing error handling patterns:
  - CLI commands print errors to stderr
  - CLI commands use `sys.exit(1)` for failures
  - Error messages should be user-friendly

### Integration Approach

- Use CLI harness from Story 11.1
- Build on existing CLI error handling patterns
- Reuse E2E foundation fixtures and utilities
- Follow existing error message patterns but validate UX contracts
- Use isolated project environments for each test

### Technology Research

- Use `pytest` for test framework
- Use `subprocess` for CLI command execution (via CLI harness)
- Use `pathlib.Path` for filesystem operations
- Use `pytest-timeout` for timeout handling (if needed)

### Risk Assessment

- **Primary risk**: UX contract validation becomes too strict and brittle
- **Mitigation**: Validate stable contracts (exit codes, error presence, stderr location); avoid over-constraining error message text
- **Rollback plan**: CLI failure path tests are additive; can be simplified or removed without affecting other tests

### Testing

- Test file location: `tests/e2e/cli/` (multiple test files)
- Test standards: Use `pytest`, follow E2E conventions from Epic 8
- Testing frameworks: `pytest`, `pytest-timeout`
- Specific requirements:
  - All tests must use `e2e_cli` marker
  - All tests must use CLI harness
  - All tests must validate exit codes (non-zero for failures)
  - All tests must validate error message presence and location (stderr)
  - All tests must validate user-actionable quality
  - All tests must use isolated project environments
  - All tests must capture failure artifacts
  - Tests should run in reasonable time (optimize as needed)

## Change Log

| Date       | Version | Description                       | Author      |
| ---------- | ------- | --------------------------------- | ----------- |
| 2025-01-XX | 0.1     | Initial draft for Epic 11.3       | bmad-master |

## Dev Agent Record

### Agent Model Used

_TBD_

### Debug Log References

_TBD_

### Completion Notes List

_TBD_

### File List

_TBD_

## QA Results

_TBD_
