# Story 16.1: Fix Weak Assertions in Core Tests

<!-- Source: implementation/cursor/EPIC_16_Unit_Test_Weak_Assertions.md -->
<!-- Context: Replace weak, permissive assertions with specific validations that verify correctness -->

## Status

**Deferred** - Testing infrastructure improvement, lower priority

## Story

**As a** developer/maintainer,
**I want** unit tests to use specific, meaningful assertions that validate actual behavior,
**so that** tests fail when functionality is broken and provide confidence that code works correctly.

## Acceptance Criteria

1. All `>= 0` assertions in `test_cleanup.py` and `test_scoring.py` are replaced with specific expected values that validate actual behavior.
2. All `is not None` checks in `test_agent_base.py` and `test_workflow_executor.py` are replaced with assertions that validate actual values and structure.
3. Broad exception matching (e.g., `(ValueError, FileNotFoundError)`) is replaced with specific exception types and error message validation.
4. Tests validate specific expected outcomes for scoring, cleanup, and workflow execution results, not just that methods don't crash.
5. All modified tests fail when functionality is intentionally broken, demonstrating they catch real issues.

## Tasks / Subtasks

- [ ] Task 1: Fix weak assertions in `test_cleanup.py` (AC: 1)
  - [ ] Replace `assert result.entries_removed >= 0` (line 240) with specific expected count
  - [ ] Replace `assert result.entries_removed >= 0` (line 256) with validation that entries were actually removed
  - [ ] Replace `assert result.entries_removed >= 0` (line 271) with validation of unused entry removal
  - [ ] Add assertions that verify cleanup actually removed entries from cache
  - [ ] Validate size calculations are correct after cleanup

- [ ] Task 2: Fix weak assertions in `test_scoring.py` (AC: 1, 4)
  - [ ] Replace `>= 0` and `<= 10` assertions (lines 58-67) with specific expected score ranges based on code complexity
  - [ ] Replace permissive assertions (lines 82-87) with specific score validations
  - [ ] Fix security score assertions (lines 98-103) to validate that insecure code scores lower
  - [ ] Replace "Allow for JSON parsing differences" assertion (line 335) with specific expected score validation
  - [ ] Add assertions that verify scoring logic produces expected relative scores

- [ ] Task 3: Fix `is not None` checks in `test_agent_base.py` (AC: 2)
  - [ ] Replace check at line 103-105 to validate config is actually loaded correctly, not just that `activate` doesn't crash
  - [ ] Add assertion at line 138 to validate customizations are actually loaded (currently only has comment)
  - [ ] Fix path traversal test at line 280-283 to validate specific exception type and error message, not just that either ValueError OR FileNotFoundError is raised

- [ ] Task 4: Fix `is not None` checks in `test_workflow_executor.py` (AC: 2, 4)
  - [ ] Replace `result is not None` check at line 276 with validation of consultation result structure
  - [ ] Replace `result is None` check at line 296 with validation of why result should be None (or what it should contain)
  - [ ] Add assertions that validate workflow execution produces expected results

- [ ] Task 5: Fix broad exception matching (AC: 3)
  - [ ] Review all exception matching patterns across modified test files
  - [ ] Replace broad exception tuples with specific exception types
  - [ ] Add error message validation to exception tests
  - [ ] Ensure exception tests validate the correct error is raised for the right reason

- [ ] Task 6: Validation testing (AC: 5)
  - [ ] Intentionally break functionality in production code
  - [ ] Verify that fixed tests now fail appropriately
  - [ ] Document that tests catch real issues

## Dev Notes

### Existing System Context

- Unit tests exist in `tests/unit/` directory
- Test fixtures in `tests/conftest.py` provide common setup
- Current tests use weak assertions that don't validate actual behavior:
  - `test_cleanup.py`: Uses `>= 0` assertions that always pass
  - `test_scoring.py`: Uses permissive range checks that don't validate scoring logic
  - `test_agent_base.py`: Checks that methods don't crash but doesn't validate results
  - `test_workflow_executor.py`: Checks for None/not None but doesn't validate structure

### Integration Approach

- Update existing test files without changing test structure
- Maintain compatibility with existing fixtures
- Keep test organization and naming conventions
- No changes to production code required

### Risk Assessment

- **Primary risk**: Fixing assertions may reveal existing bugs in production code
- **Mitigation**: 
  - Fix tests incrementally by file
  - Document any bugs discovered during test fixes
  - Prioritize high-risk test files first (cleanup, scoring)
- **Secondary risk**: Tests may become more brittle if expected values are too specific
- **Mitigation**: Use reasonable ranges for scores where exact values may vary, but validate relative correctness

### Rollback Plan

- Test changes can be reverted independently
- No impact on production code
- Can fix tests in phases, reverting individual files if needed

### Testing

- Use `pytest` to run modified tests
- Verify tests fail when functionality is intentionally broken
- Ensure test execution time doesn't significantly increase
- Run full test suite to ensure no regressions

## Change Log

| Date       | Version | Description                | Author      |
| ---------- | ------- | -------------------------- | ----------- |
| 2025-01-13 | 0.1     | Initial draft for Epic 16.1 | bmad-master |

## Dev Agent Record

### Agent Model Used

_TBD_

### Debug Log References

_TBD_

### Completion Notes List

- _TBD_

### File List

**Files to Modify:**
- `tests/unit/test_cleanup.py` - Fix weak assertions
- `tests/unit/test_scoring.py` - Fix permissive score checks
- `tests/unit/test_agent_base.py` - Fix `is not None` checks
- `tests/unit/test_workflow_executor.py` - Fix result validation

## QA Results

_TBD_

