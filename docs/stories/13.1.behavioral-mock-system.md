# Story 13.1: Behavioral Mock System

<!-- Source: implementation/cursor/EPIC_13_E2E_Functional_Validation.md -->
<!-- Context: Replace generic mock_mal with agent-specific behavioral mocks that simulate real agent behavior -->

## Status

Draft

## Story

**As a** QA engineer and developer,
**I want** agent-specific behavioral mocks that simulate real agent behavior (command parsing, response generation, error handling),
**so that** E2E tests validate actual functionality rather than just checking that mocks return generic responses.

## Acceptance Criteria

1. A behavioral mock system exists in `tests/e2e/fixtures/mock_agents.py` that provides agent-specific mock factories.
2. Each agent type (planner, implementer, reviewer, tester, etc.) has a dedicated mock that simulates its specific behavior:
   - Planner mocks generate planning artifacts (task lists, dependencies)
   - Implementer mocks generate code changes based on input requirements
   - Reviewer mocks generate review feedback and suggestions
   - Tester mocks generate test code and test results
   - Other agents have appropriate behavioral mocks
3. Behavioral mocks simulate command parsing and validation (e.g., Cursor command parsing, tool calls).
4. Behavioral mocks handle error cases and edge cases (invalid commands, missing files, etc.).
5. Behavioral mocks generate contextually appropriate responses based on input (not just "Mock LLM response").
6. Existing tests can opt-in to use behavioral mocks (backward compatible with generic `mock_mal`).
7. Behavioral mocks are well-documented with usage examples.
8. Unit tests exist for the behavioral mock system itself.

## Tasks / Subtasks

- [ ] Task 1: Design behavioral mock architecture (AC: 1, 2)
  - [ ] Analyze existing agent types and their expected behaviors
  - [ ] Design mock factory pattern for agent-specific mocks
  - [ ] Define interface for behavioral mocks (command parsing, response generation, error handling)
  - [ ] Document behavioral mock requirements for each agent type

- [ ] Task 2: Implement core behavioral mock infrastructure (AC: 1, 3, 4)
  - [ ] Create `tests/e2e/fixtures/mock_agents.py` module
  - [ ] Implement base `BehavioralMock` class with command parsing utilities
  - [ ] Implement error handling simulation (invalid commands, missing files, etc.)
  - [ ] Add utilities for parsing Cursor commands and tool calls

- [ ] Task 3: Implement agent-specific behavioral mocks (AC: 2, 5)
  - [ ] Implement `MockPlanner` that generates planning artifacts (task lists, dependencies)
  - [ ] Implement `MockImplementer` that generates code changes based on requirements
  - [ ] Implement `MockReviewer` that generates review feedback
  - [ ] Implement `MockTester` that generates test code and results
  - [ ] Implement mocks for other agent types (architect, designer, debugger, documenter, etc.)
  - [ ] Ensure each mock generates contextually appropriate responses

- [ ] Task 4: Create mock factory and fixtures (AC: 6)
  - [ ] Create `create_behavioral_mock(agent_type, **kwargs)` factory function
  - [ ] Create pytest fixtures for each agent type's behavioral mock
  - [ ] Ensure backward compatibility (existing tests can still use generic `mock_mal`)
  - [ ] Add opt-in mechanism for behavioral mocks in test configuration

- [ ] Task 5: Documentation and testing (AC: 7, 8)
  - [ ] Document behavioral mock system in `tests/e2e/fixtures/README.md`
  - [ ] Add usage examples for each agent type
  - [ ] Create unit tests for behavioral mocks in `tests/unit/e2e/test_mock_agents.py`
  - [ ] Test command parsing, response generation, and error handling

## Dev Notes

### Existing System Context

- Current mock system:
  - `tests/conftest.py` contains `mock_mal` fixture that returns generic "Mock LLM response"
  - `mock_mal_with_response` factory allows custom responses but doesn't simulate behavior
  - Tests use `mock_mal` to avoid real LLM calls but don't validate agent behavior
- Agent system:
  - Agents defined in `tapps_agents/agents/` with base class `tapps_agents/core/agent_base.py`
  - Agent types: planner, implementer, reviewer, tester, architect, designer, debugger, documenter, analyst, ops, orchestrator, enhancer
  - Agents use MAL (Model Abstraction Layer) for LLM calls via `mal.generate()`
  - Agents parse Cursor commands and tool calls from LLM responses
- E2E test structure:
  - `tests/e2e/fixtures/` contains E2E harness utilities
  - `tests/e2e/workflows/` contains workflow tests
  - `tests/e2e/scenarios/` contains scenario tests
  - Tests currently use generic `mock_mal` fixture

### Integration Approach

- Build on existing `mock_mal` fixture pattern; extend rather than replace
- Create new `mock_agents.py` module in `tests/e2e/fixtures/`
- Behavioral mocks should implement same interface as `MAL` for compatibility
- Add new fixtures alongside existing ones (backward compatible)
- Update existing tests incrementally to use behavioral mocks

### Technology Research

- Use `unittest.mock` (MagicMock, AsyncMock) for mocking infrastructure
- Use `pytest` fixtures for test integration
- Parse Cursor command format from actual agent implementations
- Study agent implementations to understand expected behaviors

### Risk Assessment

- **Primary risk**: Behavioral mocks become complex and hard to maintain
- **Mitigation**: Keep mocks focused and well-documented; provide clear examples
- **Rollback plan**: Behavioral mocks are opt-in; existing tests continue to work with generic mocks

### Testing

- Test file location: `tests/unit/e2e/test_mock_agents.py`
- Test standards: Use `pytest`, follow existing unit test patterns
- Testing frameworks: `pytest`, `pytest-asyncio` for async mocks
- Specific requirements:
  - Test command parsing for each agent type
  - Test response generation based on input
  - Test error handling simulation
  - Test backward compatibility with existing tests
  - Test mock factory functionality

## Change Log

| Date       | Version | Description                       | Author      |
| ---------- | ------- | --------------------------------- | ----------- |
| 2025-01-XX | 0.1     | Initial draft for Epic 13.1       | bmad-master |

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

### Debug Log References

_To be populated by dev agent_

### Completion Notes List

_To be populated by dev agent_

### File List

_To be populated by dev agent_

## QA Results

_To be populated by QA agent_

