# Story 2.1: Background Cloud Agents - Quality & Testing

<!-- Source: implementation/cursor/EPIC_02_Core_Agents.md -->
<!-- Context: Brownfield enhancement to run quality + testing via Cursor Background Agents -->

## Status

Draft

## Story

**As a** workflow executor running in Cursor mode,
**I want** Quality and Testing analysis to run as Background Agents that emit versioned, machine-readable results,
**so that** we can validate code quality and test coverage in parallel without blocking the IDE or corrupting the repo.

## Acceptance Criteria

1. Quality and Testing runs can be triggered in Cursor mode via Background Agent API when available (`tapps_agents/workflow/background_agent_api.py`) and fall back to file-based execution instructions when not.
2. Each run produces **machine-readable JSON artifacts** with an explicit `schema_version` (and stable field names), plus optional markdown summaries, written inside the step worktree.
3. Outputs are deterministic and bounded:
   - Quality output includes (at minimum) lint/type/security/complexity/duplication signals, or a clear “tool unavailable” status per check.
   - Testing output includes test results + coverage summary, or a clear “not run” explanation.
4. Runs are time-bounded and cancellable at the executor/orchestrator level; partial results are still written (status + error) when cancelled or timed out.
5. Workflow completion detection works using existing artifact/polling mechanisms (`tapps_agents/workflow/cursor_skill_helper.py::check_skill_completion`) without requiring manual intervention.
6. Tests cover:
   - Command generation / mapping for Quality and Testing runs.
   - Background-Agent-API unavailable path (fallback) and still producing artifacts.

## Tasks / Subtasks

- [ ] Task 1: Audit existing quality + testing capabilities (AC: 3)
  - [ ] Review `tapps_agents/agents/reviewer/agent.py` (Ruff/mypy/duplication/reporting)
  - [ ] Review `tapps_agents/agents/tester/agent.py` and existing test workflows
  - [ ] Decide whether to implement separate “quality/testing” agents vs running existing `reviewer`/`tester` as background jobs

- [ ] Task 2: Define contract + artifacts for Quality results (AC: 2–3)
  - [ ] Create a versioned JSON shape for quality output (schema_version, status, tool results, errors)
  - [ ] Define deterministic artifact paths under the worktree (e.g., `reports/quality/quality-report.json`)

- [ ] Task 3: Define contract + artifacts for Testing results (AC: 2–3)
  - [ ] Create a versioned JSON shape for test output (schema_version, status, tool results, errors)
  - [ ] Define deterministic artifact paths under the worktree (e.g., `reports/tests/test-report.json`, coverage summary)

- [ ] Task 4: Wire Background Agent triggering + fallback execution (AC: 1, 5)
  - [ ] Integrate with `tapps_agents/workflow/skill_invoker.py` command mapping and/or workflow step actions
  - [ ] Ensure fallback writes `.cursor-skill-command*.txt` + `.cursor-skill-instructions.md` in the worktree

- [ ] Task 5: Timeouts, cancellation, and bounded resource behavior (AC: 4)
  - [ ] Ensure the executor/orchestrator can cancel waiting loops and record terminal status
  - [ ] Ensure large outputs are bounded (summary fields, capped error output)

- [ ] Task 6: Tests (AC: 6)
  - [ ] Add unit tests under `tests/unit/` for command mapping + completion detection
  - [ ] Add integration tests under `tests/integration/` (mock API + fallback path) to assert artifacts are produced

## Dev Notes

### Existing System Context

- Cursor-mode workflow execution is implemented in `tapps_agents/workflow/cursor_executor.py`.
- Skill command construction and execution routing (API vs file-based) is handled by `tapps_agents/workflow/skill_invoker.py`.
- Background Agent API client lives in `tapps_agents/workflow/background_agent_api.py`.
- Fallback “write command files + instructions” is implemented in `tapps_agents/workflow/cursor_skill_helper.py`.
- Quality scoring + optional tooling already exists in `tapps_agents/agents/reviewer/agent.py` (Ruff/mypy/duplication/reporting).

### Integration Approach

- Prefer **reusing existing agent implementations** (Reviewer/Tester) while adding a clear “background execution” pathway that:
  - produces stable JSON artifacts in the worktree
  - can be triggered by the Cursor executor via Background Agent API or fallback command files
- Keep artifacts in the worktree to align with git-worktree isolation and avoid cross-step contamination.

### Risk Assessment

- **Primary risk**: tool availability differences between local IDE and Background Agent environment produce inconsistent results.
- **Mitigation**: always emit per-tool availability + error fields in the JSON result and keep outputs schema-stable.

### Rollback Plan

- Disable background execution for these checks and run the existing sequential path (or skip with “not run” artifacts) without breaking workflow execution.

### Testing

- Extend unit coverage in `tests/unit/` (see existing `tests/unit/test_workflow_executor.py`).
- Extend integration coverage (see existing `tests/integration/test_reviewer_agent.py`).

## Change Log

| Date       | Version | Description                           | Author      |
| ---------- | ------- | ------------------------------------- | ----------- |
| 2025-12-14 | 0.1     | Initial draft for Epic 2.1            | bmad-master |

## Dev Agent Record

### Agent Model Used

_TBD_

### Debug Log References

_TBD_

### Completion Notes List

- _TBD_

### File List

- _TBD_

## QA Results

_TBD_
