# Story 11.1: CLI E2E Harness + Output Capture

<!-- Source: implementation/cursor/EPIC_11_E2E_CLI_Tests.md -->
<!-- Context: Create CLI E2E harness with subprocess runner utilities, output capture, and artifact capture for failed CLI runs -->

## Status

Draft

## Story

**As a** QA engineer and developer,
**I want** a CLI E2E harness with subprocess runner utilities, output capture, and artifact capture for failed CLI runs,
**so that** CLI E2E tests can execute commands in isolated environments, capture outputs reliably, and produce actionable debug information on failures.

## Acceptance Criteria

1. A CLI E2E harness exists in `tests/e2e/fixtures/cli_runner.py` that provides:
   - `run_cli_command(command, args, cwd, env, timeout)` - runs CLI command in subprocess
   - `capture_cli_output(command, args, cwd, env, timeout)` - runs command and captures stdout/stderr/exit_code
   - `assert_cli_success(result)` - validates successful command execution
   - `assert_cli_failure(result, expected_exit_code)` - validates failed command execution
   - `assert_cli_output_contract(result, expected_keys, output_format)` - validates output contracts
2. Subprocess runner utilities support:
   - **CWD isolation**: each CLI run uses isolated temporary directory (never mutates developer's working copy)
   - **Environment injection**: support for injecting environment variables (credentials, config paths, etc.)
   - **Timeout handling**: explicit timeouts per command with graceful timeout handling
   - **Cross-platform support**: Windows-friendly path handling, quoting, and subprocess invocation
3. Output capture utilities support:
   - **stdout capture**: capture standard output (text and JSON)
   - **stderr capture**: capture standard error output
   - **Exit code capture**: capture and validate exit codes
   - **Output format detection**: detect JSON vs text output
   - **Output parsing**: parse JSON output for contract validation
4. Artifact capture for failed CLI runs:
   - Capture stdout/stderr on failure
   - Capture exit code and command executed
   - Capture working directory state (files created/modified)
   - Capture environment variables (redacted for secrets)
   - Create failure bundle with all captured information
5. Security hygiene for output capture:
   - **Secret redaction**: redact secrets from stdout/stderr before publishing
   - **PII redaction**: redact PII from captured output
   - **Credential masking**: mask API keys, tokens, passwords in captured output
   - **Safe artifact publishing**: ensure failure bundles are safe to upload in CI
6. CLI harness integrates with E2E foundation:
   - Uses E2E harness project templates for isolated test projects
   - Uses E2E artifact capture utilities
   - Uses E2E correlation IDs
   - Follows E2E conventions (timeouts, logging, failure bundles)
7. CLI harness supports Windows correctness:
   - Windows-friendly path handling (use `pathlib.Path`)
   - Proper quoting for command arguments
   - No shell-specific separators or assumptions
   - Tested on Windows platform
8. Unit tests exist for CLI harness utilities.
9. Documentation exists for using the CLI harness in E2E tests.

## Tasks / Subtasks

- [ ] Task 1: Create CLI runner core utilities (AC: 1, 2)
  - [ ] Create `tests/e2e/fixtures/cli_runner.py`
  - [ ] Implement `run_cli_command()` function (subprocess execution)
  - [ ] Implement `capture_cli_output()` function (stdout/stderr/exit_code capture)
  - [ ] Add CWD isolation (temp directory per test)
  - [ ] Add environment variable injection support
  - [ ] Add timeout handling
  - [ ] Ensure Windows-friendly implementation

- [ ] Task 2: Implement output capture utilities (AC: 3)
  - [ ] Implement stdout capture (text and JSON)
  - [ ] Implement stderr capture
  - [ ] Implement exit code capture
  - [ ] Implement output format detection (JSON vs text)
  - [ ] Implement JSON output parsing
  - [ ] Create result object with captured outputs

- [ ] Task 3: Implement assertion utilities (AC: 1)
  - [ ] Implement `assert_cli_success()` (validates exit_code == 0)
  - [ ] Implement `assert_cli_failure()` (validates exit_code != 0, expected exit code)
  - [ ] Implement `assert_cli_output_contract()` (validates JSON shape, required keys)
  - [ ] Provide clear assertion error messages

- [ ] Task 4: Implement artifact capture for failures (AC: 4)
  - [ ] Capture stdout/stderr on failure
  - [ ] Capture exit code and command executed
  - [ ] Capture working directory state (files created/modified)
  - [ ] Capture environment variables (redacted)
  - [ ] Create failure bundle with all captured information
  - [ ] Integrate with E2E artifact capture utilities

- [ ] Task 5: Implement security hygiene (AC: 5)
  - [ ] Implement secret redaction from stdout/stderr
  - [ ] Implement PII redaction
  - [ ] Implement credential masking (API keys, tokens, passwords)
  - [ ] Ensure failure bundles are safe to publish
  - [ ] Add redaction configuration (patterns, keywords)

- [ ] Task 6: Integrate with E2E foundation (AC: 6)
  - [ ] Use E2E harness project templates for test projects
  - [ ] Use E2E artifact capture utilities
  - [ ] Use E2E correlation IDs
  - [ ] Follow E2E conventions (timeouts, logging, failure bundles)
  - [ ] Integrate with E2E fixtures in `tests/e2e/conftest.py`

- [ ] Task 7: Ensure Windows correctness (AC: 7)
  - [ ] Use `pathlib.Path` for all path operations
  - [ ] Proper quoting for command arguments
  - [ ] Avoid shell-specific separators
  - [ ] Test on Windows platform
  - [ ] Document Windows-specific considerations

- [ ] Task 8: Create pytest fixtures for CLI runner (AC: 1, 6)
  - [ ] Add `cli_runner` fixture to `tests/e2e/conftest.py`
  - [ ] Add `cli_project` fixture (isolated project for CLI tests)
  - [ ] Add `cli_output_capture` fixture (automatic output capture)
  - [ ] Add `cli_env` fixture (environment variable injection)
  - [ ] Integrate with existing E2E fixtures

- [ ] Task 9: Unit tests and documentation (AC: 8, 9)
  - [ ] Create unit tests in `tests/unit/e2e/test_cli_runner.py`
  - [ ] Test CLI runner utilities (run, capture, assert)
  - [ ] Test output capture (stdout, stderr, exit code)
  - [ ] Test artifact capture on failure
  - [ ] Test secret redaction
  - [ ] Test Windows path handling
  - [ ] Document CLI harness usage in `tests/e2e/cli/README.md`
  - [ ] Provide example E2E test using CLI harness

## Dev Notes

### Existing System Context

- CLI entry point:
  - `tapps_agents/cli.py` - CLI main entry point
  - Commands: `review`, `score`, `plan`, `workflow`, `init`, `doctor`, etc.
  - Execution: `python -m tapps_agents.cli <command> <args>`
- E2E foundation (from Epic 8):
  - `tests/e2e/fixtures/e2e_harness.py` - E2E harness utilities
  - `tests/e2e/fixtures/project_templates.py` - project templates
  - `tests/e2e/conftest.py` - E2E fixtures
- Existing integration tests:
  - `tests/integration/test_cli_create_timeline_verification.py` - CLI create command test
  - `tests/integration/test_cli_create_cursor_ide_timeline.py` - CLI create command test
- Existing subprocess patterns:
  - Some integration tests use subprocess (check existing patterns)

### Integration Approach

- Build on existing CLI entry point (`python -m tapps_agents.cli`)
- Use subprocess for isolated command execution
- Reuse E2E harness utilities for project setup and artifact capture
- Follow existing patterns for subprocess execution in integration tests
- Ensure Windows compatibility from the start

### Technology Research

- Use `subprocess` module for command execution
- Use `pathlib.Path` for cross-platform path handling
- Use `pytest` fixtures for CLI runner
- Use `json` for JSON output parsing
- Use `re` or similar for secret redaction patterns
- Use `pytest-timeout` for timeout handling (if needed)

### Risk Assessment

- **Primary risk**: CLI harness becomes complex or Windows-incompatible
- **Mitigation**: Test on Windows from the start; keep harness focused; provide clear examples
- **Rollback plan**: CLI harness is additive; can be simplified or removed without affecting other tests

### Testing

- Test file location: `tests/unit/e2e/test_cli_runner.py`
- Test standards: Use `pytest`, follow existing unit test patterns
- Testing frameworks: `pytest`
- Specific requirements:
  - Test CLI command execution (success and failure)
  - Test output capture (stdout, stderr, exit code)
  - Test artifact capture on failure
  - Test secret redaction
  - Test Windows path handling
  - Test environment variable injection
  - Test timeout handling

## Change Log

| Date       | Version | Description                       | Author      |
| ---------- | ------- | --------------------------------- | ----------- |
| 2025-01-XX | 0.1     | Initial draft for Epic 11.1       | bmad-master |

## Dev Agent Record

### Agent Model Used

_TBD_

### Debug Log References

_TBD_

### Completion Notes List

_TBD_

### File List

_TBD_

## QA Results

_TBD_
